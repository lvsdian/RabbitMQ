[TOC]

## 消息队列

### 优点
#### 解耦
- **场景**：A系统 发送数据到B、C、D三个系统，通过接口调用发送。这里A系统跟其它系统严重耦合，如果现在E系统也需要这个数据或者C系统现在不需要了，需要去修改A系统的代码。
- **使用MQ**：A系统的数据发到MQ里，其他系统需要就去MQ里面取就行了，不需要这些数据就取消对MQ的消费即可。
#### 异步
- **场景**：A系统收到一个请求，自己需要落库耗时100ms，还要在B、C、D三个系统落库分别需要300ms、450ms、200ms，总计耗时接近1s，一般要求是200ms。
- **使用MQ**：A自己落库，并发3条请求到MQ，假设每条10ms，总计耗时130ms
#### 削峰
- **场景**：每天晚上A的TPS为50，中午TPS暴增到5k+。一般的MySQL，TPS最多也就2k，如果5k的话，mysql就会直接崩溃。但是高峰期一过，TPS就又恢复到了50，整个系统几乎没有任何的压力。
- **使用MQ**：每秒 5k 个请求写入 MQ，A系统从MQ中慢慢拉取请求，每秒拉取 2k 个请求，这样下来，哪怕是高峰期的时候，A 系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，就 2k 
个请求出去，就导致在中午高峰期，可能有几十万甚至几百万的请求积压在 MQ 中。高峰期过了之后，每秒钟就 50 个请求进 MQ，但是 A 系统依然会按照每秒 2k 个请求的速度在处理。
只要高峰期一过，A 系统就会快速将积压的消息给解决掉。
### 缺点
- 系统可用性降低：MQ一旦挂掉，整套系统崩溃。
- 系统复杂性提高：要保证没有重复消费、可靠性投递，保证消息传递的顺序性。
- 一致性问题：A 系统处理完了直接返回成功了，但是BCD三个系统中BD写库成功了，C写库失败，导致数据不一致。
### 消息队列高可用

- rabbitmq**基于主从（非分布式）**做高可用性。

1. 单机，demo级别。

2. 普通集群模式

  - 原理：在多台机器上启动多个rabbitmq实例，每个机器启动一个。你创建的queue，只会放在一个rabbtimq实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。
  - 问题：要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有**数据拉取的开销**，后者导致**单实例性能瓶颈**。 如果那个放 queue 的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你**开启了消息持久化**，让 RabbitMQ 落地存储消息的话，**消息不一定会丢**，得等这个实例恢复了，然后才可以继续从这个 queue 拉取数据。
  - 结论：**没有做到高可用性**，**只是提高吞吐量**
  
2. 镜像集群模式
   - 原理：镜像集群模式下，创建的 queue，无论元数据还是 queue 里的消息都会**存在于多个实例上**，就是说，每个 RabbitMQ 节点都有这个 queue 的一个**完整镜像**，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把**消息同步**到多个实例的 queue 上。
   - 开启方法：在rabbitmq管理后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候可以要求数据同步到所有节点的，也可以要求就同步到指定数量的节点，然后你再次创建queue的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。
   - 好处：任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。
   - 坏处：
     - 第一，这个性能开销太大了，消息同步所有机器，导致网络带宽压力和消耗很重！
     - 第二，不是分布式的，就没有扩展性可言，如果某个queue负载很重，加机器，新增的机器也包含了这个queue的所有数据，并没有办法线性扩展你的queue。

### 如何保证消息可靠性传输

1. 生产者丢失数据  
    - 开启confirm模式。在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了rabbitmq中，rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。  
    - 事务机制(影响性能)和cnofirm机制最大的不同在于：事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后rabbitmq接收了那个消息之后会异步回调你一个接口通知你这个消息接收到了。
2. rabbitmq丢失数据  
    - 开启rabbitmq的持久化。就是消息写入之后会持久化到磁盘，哪怕是rabbitmq自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。
    - 设置持久化有两个步骤，
        - 第一个是创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，但是不会持久化queue里的数据；
        - 第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时rabbitmq就会将消息持久化到磁盘上去。
    - 必须要同时设置这两个持久化才行。rabbitmq哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。
    - 有一种可能，就是这个消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。所以，持久化可以和 `confirm` 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 `ack` 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 `ack`，你也是可以自己重发的。
3. 消费端弄丢了数据  
    - 消费的时候，刚消费到，还没处理，结果进程挂了，RabbitMQ 会认为消费过了，这时数据就丢了。这个时候必须关闭 RabbitMQ 的自动 `ack`，可以通过一个 api 来调用就行，然后代码里确保处理完的时候，在程序里 `ack` 一下。这样的话，如果还没处理进程就挂了，RabbitMQ会认为还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。

### 如何保证消息不被重复消费(保证幂等性)  

- 每次重启系统，可能会有消息被重复消费，此时就需要保证幂等性(幂等：同一条件下，对同一个业务的操作，不管操作多少次，结果都一样。)

1. 如果消费者是写入数据库，可以先根据主键查一下，如果这数据已经有了就直接update
2. 如果是写入redis，那没问题了，反正每次都是set，天然幂等性
3. 如果不是上面两个场景，那做的稍微复杂一点，让生产者发送每条数据的时候，里面加一个全局唯一的 id，然后消费到了之后，先根据这个 id 去比如 Redis 里查一下是否消费过。如果没有消费过就处理，然后把这个id写入Redis。如果消费过就忽略。
4. 基于数据库的唯一键来保证重复数据不会重复插入多条。重复数据插入的时候，因为有唯一键约束了，所以重复数据只会插入报错，不会导致数据库中出现脏数据。

### 如何保证消息顺序性

1. 场景：一个queue，多个consumer。比如，生产者向 RabbitMQ 里发送了三条数据，顺序依次是 data1/data2/data3，压入的是 RabbitMQ 的一个内存队列。有三个消费者分别从 MQ 中消费这三条数据中的一条，结果消费者2先执行完操作，把 data2 存入数据库，然后是 data1/data3。这不明显乱了。
2. 方案：拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理。

### 消息延迟、积压

1. 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决?   
    - 场景一：比如消费端每次消费要写入mysql，结果mysql挂了，消费端不能消费了或者消费速度及其慢，这时大量消息就会堆积在队列中。
    - 解决方案(**临时紧急扩容**)：
        1. 先修复consumer问题，确保其恢复消费速度，然后将现有consumer都停掉。
        2. 新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量
        3. 然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue
        4. 接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据
        5. 这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据
        6. 等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息
    - 场景二：rabbitmq中大量积压的消息设置了过期时间TTL，积压超过一定的时间就会被rabbitmq给清理掉，这个数据就没了。
    - 解决方案(**批量重导**)：高峰期过后，将白天丢失的数据查出来再放到mq里面。
    - 场景三：消息长时间积压，导致mq快写满了
    - 解决方法：**消费一个丢弃一个，都不要了**，快速消费掉所有的消息。再走场景二的解决方案。

### 如果让你写一个消息队列，该如何进行架构设计啊？说一下你的思路

- 需要支持可扩展性，需要时可以快速扩容
- 需要落地磁盘，才能保证进程挂掉时数据不会丢失。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的     
- 需要保证可用性
- 需要支持数据0丢失